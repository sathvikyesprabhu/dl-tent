{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dD2JIKNXlul"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install torchattacks\n",
        "from torchattacks import PGD\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDBJ0vkYXluo"
      },
      "outputs": [],
      "source": [
        "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "pretrained_model = \"data/lenet_mnist_model.pth\"\n",
        "use_cuda=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKC4xXYaXlur"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(1,16,5), # 16*24*24\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16,32,5), # 32*20*20\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2,2), # 32*10*10\n",
        "            nn.Conv2d(32,64,5), # 64*6*6\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2,2) #64*3*3\n",
        "        )\n",
        "        \n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*3*3,100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,10)\n",
        "        )       \n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = self.layer(x)\n",
        "        out = out.view(-1,64*3*3)\n",
        "        out = self.fc_layer(out)\n",
        "\n",
        "        return F.log_softmax(out, dim=1)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])), \n",
        "        batch_size=1, shuffle=True)\n",
        "\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
        "model = Net().to(device)\n",
        "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGdrLBJNXluv"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image\n",
        "\n",
        "def pgd_attack(image,eps,model,label):\n",
        "  atk = PGD(model, eps=0.3, alpha=0.1, steps=7)\n",
        "  return atk(image,label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRZgYEgsXluy"
      },
      "outputs": [],
      "source": [
        "def test( model, device, test_loader, epsilon ):\n",
        "\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        data.requires_grad = True\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] \n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "        loss = F.nll_loss(output, target)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        data_grad = data.grad.data\n",
        "        perturbed_data=pgd_attack(data,epsilon, model,target)\n",
        "        output = model(perturbed_data)\n",
        "        final_pred = output.max(1, keepdim=True)[1] \n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "        else:\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "    final_acc = correct/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "    return final_acc, adv_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQPNHuUNXlu2"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "for eps in epsilons:\n",
        "    acc, ex = test(model, device, test_loader, eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPHFIvs6Xlu3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons, accuracies, \"*-\")\n",
        "plt.yticks(np.arange(0, 0.1, step=0.1))\n",
        "plt.xticks(np.arange(0, .35, step=0.05))\n",
        "plt.title(\"Accuracy vs Epsilon\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()\n",
        "plt.savefig(\"PGD_eps_vs_acc.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEcO_kUSXlu6"
      },
      "outputs": [],
      "source": [
        "cnt = 0\n",
        "plt.figure(figsize=(8,10))\n",
        "for i in range(len(epsilons)):\n",
        "    for j in range(len(examples[i])):\n",
        "        cnt += 1\n",
        "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "        plt.xticks([], [])\n",
        "        plt.yticks([], [])\n",
        "        if j == 0:\n",
        "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "        orig,adv,ex = examples[i][j]\n",
        "        plt.title(\"{} -> {}\".format(orig, adv))\n",
        "        plt.imshow(ex, cmap=\"gray\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "Visualize_adversarial_attacks.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}