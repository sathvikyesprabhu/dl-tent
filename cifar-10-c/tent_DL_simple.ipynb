{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from networks import CNN\n",
    "import tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(32, padding=4),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean, std)\n",
    "                                    ])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean, std)])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "valset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(trainset.train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.169046 M parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3795,  0.2018, -0.1943,  0.4986, -0.0660,  0.0540,  0.0642,  0.2392,\n",
       "          0.0114, -0.2146],\n",
       "        [-0.5359,  0.1662, -0.2159,  0.3042,  0.0034, -0.4122, -0.1548,  0.1133,\n",
       "          0.0598, -0.2355]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1000000, \"M parameters\")\n",
    "x = torch.randn(2,3,32,32)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # CE Loss, Takes care of applying softmax\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # Adam optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Train loss: 1.4141 | Test loss: 1.0720 | Train acc.: 0.4871 | Test acc.: 0.6154\n",
      "\n",
      "Epoch:1 | Train loss: 1.0830 | Test loss: 0.9128 | Train acc.: 0.6135 | Test acc.: 0.6754\n",
      "\n",
      "Epoch:2 | Train loss: 0.9452 | Test loss: 0.8189 | Train acc.: 0.6662 | Test acc.: 0.7144\n",
      "\n",
      "Epoch:3 | Train loss: 0.8701 | Test loss: 0.7790 | Train acc.: 0.6932 | Test acc.: 0.7292\n",
      "\n",
      "Epoch:4 | Train loss: 0.8149 | Test loss: 0.7386 | Train acc.: 0.7134 | Test acc.: 0.7429\n",
      "\n",
      "Epoch:5 | Train loss: 0.7816 | Test loss: 0.6900 | Train acc.: 0.7241 | Test acc.: 0.7568\n",
      "\n",
      "Epoch:6 | Train loss: 0.7480 | Test loss: 0.7006 | Train acc.: 0.7385 | Test acc.: 0.7536\n",
      "\n",
      "Epoch:7 | Train loss: 0.7220 | Test loss: 0.6774 | Train acc.: 0.7465 | Test acc.: 0.7638\n",
      "\n",
      "Epoch:8 | Train loss: 0.7016 | Test loss: 0.6490 | Train acc.: 0.7527 | Test acc.: 0.7748\n",
      "\n",
      "Epoch:9 | Train loss: 0.6859 | Test loss: 0.6384 | Train acc.: 0.7609 | Test acc.: 0.7800\n",
      "\n",
      "Epoch:10 | Train loss: 0.6658 | Test loss: 0.6384 | Train acc.: 0.7646 | Test acc.: 0.7755\n",
      "\n",
      "Epoch:11 | Train loss: 0.6547 | Test loss: 0.6317 | Train acc.: 0.7705 | Test acc.: 0.7844\n",
      "\n",
      "Epoch:12 | Train loss: 0.6449 | Test loss: 0.6349 | Train acc.: 0.7729 | Test acc.: 0.7826\n",
      "\n",
      "Epoch:13 | Train loss: 0.6323 | Test loss: 0.6089 | Train acc.: 0.7769 | Test acc.: 0.7875\n",
      "\n",
      "Epoch:14 | Train loss: 0.6214 | Test loss: 0.6099 | Train acc.: 0.7817 | Test acc.: 0.7904\n",
      "\n",
      "Epoch:15 | Train loss: 0.6114 | Test loss: 0.6062 | Train acc.: 0.7830 | Test acc.: 0.7933\n",
      "\n",
      "Epoch:16 | Train loss: 0.6011 | Test loss: 0.6096 | Train acc.: 0.7888 | Test acc.: 0.7865\n",
      "\n",
      "Epoch:17 | Train loss: 0.5953 | Test loss: 0.5960 | Train acc.: 0.7930 | Test acc.: 0.7968\n",
      "\n",
      "Epoch:18 | Train loss: 0.5824 | Test loss: 0.5924 | Train acc.: 0.7962 | Test acc.: 0.7968\n",
      "\n",
      "Epoch:19 | Train loss: 0.5770 | Test loss: 0.5704 | Train acc.: 0.7973 | Test acc.: 0.8042\n",
      "\n",
      "Epoch:20 | Train loss: 0.5743 | Test loss: 0.5922 | Train acc.: 0.7993 | Test acc.: 0.7965\n",
      "\n",
      "Epoch:21 | Train loss: 0.5680 | Test loss: 0.5828 | Train acc.: 0.7999 | Test acc.: 0.7988\n",
      "\n",
      "Epoch:22 | Train loss: 0.5610 | Test loss: 0.5815 | Train acc.: 0.8037 | Test acc.: 0.8005\n",
      "\n",
      "Epoch:23 | Train loss: 0.5555 | Test loss: 0.5648 | Train acc.: 0.8064 | Test acc.: 0.8051\n",
      "\n",
      "Epoch:24 | Train loss: 0.5505 | Test loss: 0.5722 | Train acc.: 0.8053 | Test acc.: 0.8033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(25):  # num epochs\n",
    "    \n",
    "    # Training\n",
    "    model.train() # Set to train mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader): # Get data batch-wise\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # print(inputs.shape, inputs.dtype)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        # zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs) # forward pass\n",
    "        # print(outputs.shape)\n",
    "        # print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels) # Get loss\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Optimize model weights\n",
    "\n",
    "        _, preds = torch.max(outputs, 1) # Get predictions\n",
    "        running_loss += loss.detach() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # Get loss and accuracy\n",
    "    train_loss = (running_loss / len(trainset))\n",
    "    train_loss_list.append(train_loss.item())\n",
    "    train_accuracy = (running_corrects.float() / len(trainset))\n",
    "\n",
    "    # Testing\n",
    "    model.eval() # Set to eval mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    y = []; yhat = []\n",
    "\n",
    "    for i, data in enumerate(valloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        with torch.no_grad(): # Don't build computation graph for testing\n",
    "            outputs = model(inputs)\n",
    "        # print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y.append(labels.tolist())\n",
    "        yhat.append(preds.tolist())\n",
    "        running_loss += loss.detach() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    # Get loss and accuracy\n",
    "    test_loss = (running_loss / len(valset))\n",
    "    test_loss_list.append(test_loss.item())\n",
    "    test_accuracy = (running_corrects.float() / len(valset))\n",
    "\n",
    "    acc = test_accuracy.item()\n",
    "    if(acc > best_acc):\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(),\"checkpoint/cnn.pth\")\n",
    "\n",
    "    # Display loss, accuracy values after each epoch\n",
    "    print(\"Epoch:{} | Train loss: {:.4f} | Test loss: {:.4f} | Train acc.: {:.4f} | Test acc.: {:.4f}\\n\"\n",
    "              .format(epoch, train_loss.item(),test_loss.item(),train_accuracy.item(),test_accuracy.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoint/cnn.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5648 | Test acc.: 0.8051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model.eval() # Set to eval mode\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "y = []; yhat = []\n",
    "\n",
    "for i, data in enumerate(valloader):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    with torch.no_grad(): # Don't build computation graph for testing\n",
    "        outputs = model(inputs)\n",
    "    # print(outputs.shape, labels.shape)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y.append(labels.tolist())\n",
    "    yhat.append(preds.tolist())\n",
    "    running_loss += loss.detach() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "# Get loss and accuracy\n",
    "test_loss = (running_loss / len(valset))\n",
    "test_loss_list.append(test_loss.item())\n",
    "test_accuracy = (running_corrects.float() / len(valset))\n",
    "\n",
    "# Display loss, accuracy values after each epoch\n",
    "print(\"Test loss: {:.4f} | Test acc.: {:.4f}\\n\"\n",
    "            .format(test_loss.item(),test_accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENT\n",
    "\n",
    "net = tent.configure_model(model)\n",
    "params, param_names = tent.collect_params(net)\n",
    "optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "tented_model = tent.Tent(net, optimizer)\n",
    "\n",
    "tented_model = tented_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6116 | Test acc.: 0.7954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing\n",
    "tented_model.eval() # Set to eval mode\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "y = []; yhat = []\n",
    "\n",
    "for i, data in enumerate(valloader):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    with torch.no_grad(): # Don't build computation graph for testing\n",
    "        outputs = tented_model(inputs)\n",
    "    # print(outputs.shape, labels.shape)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y.append(labels.tolist())\n",
    "    yhat.append(preds.tolist())\n",
    "    running_loss += loss.detach() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "# Get loss and accuracy\n",
    "test_loss = (running_loss / len(valset))\n",
    "test_loss_list.append(test_loss.item())\n",
    "test_accuracy = (running_corrects.float() / len(valset))\n",
    "\n",
    "# Display loss, accuracy values after each epoch\n",
    "print(\"Test loss: {:.4f} | Test acc.: {:.4f}\\n\"\n",
    "            .format(test_loss.item(),test_accuracy.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.7819   brightness.npy\n",
      "Average: 0.4921   contrast.npy\n",
      "Average: 0.6456   defocus_blur.npy\n",
      "Average: 0.6737   elastic_transform.npy\n",
      "Average: 0.6544   fog.npy\n",
      "Average: 0.6426   frost.npy\n",
      "Average: 0.5719   gaussian_blur.npy\n",
      "Average: 0.5597   gaussian_noise.npy\n",
      "Average: 0.4561   glass_blur.npy\n",
      "Average: 0.5126   impulse_noise.npy\n",
      "Average: 0.7309   jpeg_compression.npy\n",
      "Average: 0.5918   motion_blur.npy\n",
      "Average: 0.6247   pixelate.npy\n",
      "Average: 0.7466   saturate.npy\n",
      "Average: 0.6178   shot_noise.npy\n",
      "Average: 0.6547   snow.npy\n",
      "Average: 0.706   spatter.npy\n",
      "Average: 0.6216   speckle_noise.npy\n",
      "Average: 0.5778   zoom_blur.npy\n",
      "Mean:  0.6243263034444105\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoint/cnn.pth\"))\n",
    "\n",
    "chalPath = 'data/CIFAR-10-C/'\n",
    "chals = sorted(os.listdir(chalPath))\n",
    "\n",
    "chal_labels = valset.test_labels\n",
    "chal_labels = torch.Tensor(chal_labels)\n",
    "chal_labels = chal_labels.long()\n",
    "\n",
    "def preprocess_test(X):\n",
    "\n",
    "    N, H, W, C = X.shape\n",
    "    Y = torch.zeros(N, C, H, W)\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)  \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean,std),\n",
    "    ])\n",
    "\n",
    "    for n in range(len(X)):\n",
    "        Y[n] =  transform_test(X[n])\n",
    "\n",
    "    return Y\n",
    "\n",
    "model.eval()\n",
    "avg_list = []\n",
    "\n",
    "for challenge in range(len(chals)):\n",
    "    chal_data = np.load(chalPath + chals[challenge])\n",
    "    # chal_data = np.transpose(chal_data, (0,3,1,2))\n",
    "\n",
    "    avg = 0\n",
    "    for j in range(5):\n",
    "        chal_temp_data = chal_data[j * 10000:(j + 1) * 10000]\n",
    "        chal_temp_data = preprocess_test(chal_temp_data)\n",
    "\n",
    "        chal_dataset = torch.utils.data.TensorDataset(chal_temp_data, chal_labels)\n",
    "        chal_loader = torch.utils.data.DataLoader(chal_dataset, batch_size=128)\n",
    "        chal_error = 0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in chal_loader:\n",
    "                # cost, err, probs = net.sample_eval(x, y, Nsamples=10, logits=False)\n",
    "                # preds_list.append(probs.cpu().numpy())\n",
    "                # chal_error += err.cpu().numpy()\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                outputs = model(x)\n",
    "                correct += torch.sum(torch.argmax(outputs,1) == y)\n",
    "            # print(err)\n",
    "\n",
    "        # print(chal_error)\n",
    "        chal_acc = (correct/len(chal_dataset)).item()\n",
    "        avg += chal_acc\n",
    "        # print(round(chal_acc,4))\n",
    "    \n",
    "    avg /= 5\n",
    "    avg_list.append(avg)\n",
    "    print(\"Average:\", round(avg,4),\" \", chals[challenge])\n",
    "\n",
    "print(\"Mean: \", np.mean(avg_list))\n",
    "list1 = avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cnn_base.npy\",avg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.7842   brightness.npy\n",
      "Average: 0.7429   contrast.npy\n",
      "Average: 0.7711   defocus_blur.npy\n",
      "Average: 0.7266   elastic_transform.npy\n",
      "Average: 0.7484   fog.npy\n",
      "Average: 0.712   frost.npy\n",
      "Average: 0.754   gaussian_blur.npy\n",
      "Average: 0.684   gaussian_noise.npy\n",
      "Average: 0.605   glass_blur.npy\n",
      "Average: 0.6445   impulse_noise.npy\n",
      "Average: 0.7323   jpeg_compression.npy\n",
      "Average: 0.7211   motion_blur.npy\n",
      "Average: 0.7366   pixelate.npy\n",
      "Average: 0.7625   saturate.npy\n",
      "Average: 0.7076   shot_noise.npy\n",
      "Average: 0.6921   snow.npy\n",
      "Average: 0.7207   spatter.npy\n",
      "Average: 0.7022   speckle_noise.npy\n",
      "Average: 0.7406   zoom_blur.npy\n",
      "Mean:  0.7204452458180881\n"
     ]
    }
   ],
   "source": [
    "# Tented\n",
    "\n",
    "chalPath = 'data/CIFAR-10-C/'\n",
    "chals = sorted(os.listdir(chalPath))\n",
    "\n",
    "chal_labels = valset.test_labels\n",
    "chal_labels = torch.Tensor(chal_labels)\n",
    "chal_labels = chal_labels.long()\n",
    "\n",
    "def preprocess_test(X):\n",
    "\n",
    "    N, H, W, C = X.shape\n",
    "    Y = torch.zeros(N, C, H, W)\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)  \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean,std),\n",
    "    ])\n",
    "\n",
    "    for n in range(len(X)):\n",
    "        Y[n] =  transform_test(X[n])\n",
    "\n",
    "    return Y\n",
    "\n",
    "avg_list = []\n",
    "\n",
    "for challenge in range(len(chals)):\n",
    "    chal_data = np.load(chalPath + chals[challenge])\n",
    "    # chal_data = np.transpose(chal_data, (0,3,1,2))\n",
    "\n",
    "    avg = 0\n",
    "    for j in range(5):\n",
    "\n",
    "        # Load tented model\n",
    "        model = CNN()\n",
    "        model.load_state_dict(torch.load(\"checkpoint/cnn.pth\"))\n",
    "        \n",
    "        net = tent.configure_model(model)\n",
    "        params, param_names = tent.collect_params(net)\n",
    "        optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "        tented_model = tent.Tent(net, optimizer)\n",
    "\n",
    "        tented_model = tented_model.to(device)\n",
    "\n",
    "        \n",
    "        chal_temp_data = chal_data[j * 10000:(j + 1) * 10000]\n",
    "        chal_temp_data = preprocess_test(chal_temp_data)\n",
    "\n",
    "        chal_dataset = torch.utils.data.TensorDataset(chal_temp_data, chal_labels)\n",
    "        chal_loader = torch.utils.data.DataLoader(chal_dataset, batch_size=128)\n",
    "        chal_error = 0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        tented_model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in chal_loader:\n",
    "                # cost, err, probs = net.sample_eval(x, y, Nsamples=10, logits=False)\n",
    "                # preds_list.append(probs.cpu().numpy())\n",
    "                # chal_error += err.cpu().numpy()\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                outputs = tented_model(x)\n",
    "                correct += torch.sum(torch.argmax(outputs,1) == y)\n",
    "            # print(err)\n",
    "\n",
    "        # print(chal_error)\n",
    "        chal_acc = (correct/len(chal_dataset)).item()\n",
    "        avg += chal_acc\n",
    "        # print(round(chal_acc,4))\n",
    "    \n",
    "    avg /= 5\n",
    "    avg_list.append(avg)\n",
    "    print(\"Average:\", round(avg,4),\" \", chals[challenge])\n",
    "\n",
    "print(\"Mean: \", np.mean(avg_list))\n",
    "list2 = avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cnn_tent.npy\",avg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = np.load(\"cnn_base.npy\")\n",
    "# list2 = np.load(\"cnn_tent.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "types = np.arange(1,20)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "x_axis = np.arange(len(types))\n",
    "plt.bar(x_axis -0.1, list1, width=0.2, label = 'Base model')\n",
    "plt.bar(x_axis +0.1, list2, width=0.2, label = 'Tented model')\n",
    "\n",
    "plt.xticks(x_axis, types)\n",
    "plt.title(\"Average accuracy per distortion type\")\n",
    "plt.legend(loc = 'upper right', framealpha = 0.1)\n",
    "\n",
    "plt.xlabel(\"Distortion type\")\n",
    "plt.ylabel(\"Average accuracy\")\n",
    "plt.savefig(\"cifar10c_cnn.pdf\",bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31b8918c388efabf28e06d7aa829f320b99f50374aee3ccc5c6fe8cd01c3acd4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
