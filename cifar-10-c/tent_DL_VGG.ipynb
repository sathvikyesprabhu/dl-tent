{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from networks import VGG16\n",
    "import tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "1\n",
      "NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(32, padding=4),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean, std)\n",
    "                                    ])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean, std)])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "valset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(trainset.train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.775446 M parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1548, -0.5619, -0.1738,  0.6957, -0.1544, -0.4640, -1.0512,  0.4781,\n",
       "         -0.3107,  0.1203],\n",
       "        [ 0.0109, -0.0459, -0.1318,  0.7003, -0.1380, -0.0315, -0.4133, -0.0752,\n",
       "          0.1881, -0.0451]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16()\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters())/1000000, \"M parameters\")\n",
    "x = torch.randn(2,3,32,32)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # CE Loss, Takes care of applying softmax\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # Adam optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 | Train loss: 1.8204 | Test loss: 1.6558 | Train acc.: 0.2832 | Test acc.: 0.3710\n",
      "\n",
      "Epoch:1 | Train loss: 1.5269 | Test loss: 1.5052 | Train acc.: 0.3988 | Test acc.: 0.4357\n",
      "\n",
      "Epoch:2 | Train loss: 1.3459 | Test loss: 1.3613 | Train acc.: 0.4910 | Test acc.: 0.5312\n",
      "\n",
      "Epoch:3 | Train loss: 1.1869 | Test loss: 1.0034 | Train acc.: 0.5706 | Test acc.: 0.6404\n",
      "\n",
      "Epoch:4 | Train loss: 1.0531 | Test loss: 0.8710 | Train acc.: 0.6315 | Test acc.: 0.7016\n",
      "\n",
      "Epoch:5 | Train loss: 0.9303 | Test loss: 0.9634 | Train acc.: 0.6842 | Test acc.: 0.6780\n",
      "\n",
      "Epoch:6 | Train loss: 0.8464 | Test loss: 0.6823 | Train acc.: 0.7199 | Test acc.: 0.7687\n",
      "\n",
      "Epoch:7 | Train loss: 0.7620 | Test loss: 0.6659 | Train acc.: 0.7511 | Test acc.: 0.7814\n",
      "\n",
      "Epoch:8 | Train loss: 0.7076 | Test loss: 0.6465 | Train acc.: 0.7727 | Test acc.: 0.7919\n",
      "\n",
      "Epoch:9 | Train loss: 0.6521 | Test loss: 0.6335 | Train acc.: 0.7947 | Test acc.: 0.8015\n",
      "\n",
      "Epoch:10 | Train loss: 0.6090 | Test loss: 0.5677 | Train acc.: 0.8115 | Test acc.: 0.8202\n",
      "\n",
      "Epoch:11 | Train loss: 0.5794 | Test loss: 0.5190 | Train acc.: 0.8210 | Test acc.: 0.8370\n",
      "\n",
      "Epoch:12 | Train loss: 0.5249 | Test loss: 0.5444 | Train acc.: 0.8400 | Test acc.: 0.8328\n",
      "\n",
      "Epoch:13 | Train loss: 0.4885 | Test loss: 0.5020 | Train acc.: 0.8502 | Test acc.: 0.8448\n",
      "\n",
      "Epoch:14 | Train loss: 0.4691 | Test loss: 0.5254 | Train acc.: 0.8577 | Test acc.: 0.8329\n",
      "\n",
      "Epoch:15 | Train loss: 0.4366 | Test loss: 0.5303 | Train acc.: 0.8663 | Test acc.: 0.8393\n",
      "\n",
      "Epoch:16 | Train loss: 0.4227 | Test loss: 0.4568 | Train acc.: 0.8707 | Test acc.: 0.8562\n",
      "\n",
      "Epoch:17 | Train loss: 0.3958 | Test loss: 0.4946 | Train acc.: 0.8804 | Test acc.: 0.8504\n",
      "\n",
      "Epoch:18 | Train loss: 0.3774 | Test loss: 0.4873 | Train acc.: 0.8854 | Test acc.: 0.8606\n",
      "\n",
      "Epoch:19 | Train loss: 0.3603 | Test loss: 0.4235 | Train acc.: 0.8910 | Test acc.: 0.8710\n",
      "\n",
      "Epoch:20 | Train loss: 0.3476 | Test loss: 0.4640 | Train acc.: 0.8949 | Test acc.: 0.8648\n",
      "\n",
      "Epoch:21 | Train loss: 0.3263 | Test loss: 0.4144 | Train acc.: 0.8995 | Test acc.: 0.8732\n",
      "\n",
      "Epoch:22 | Train loss: 0.3114 | Test loss: 0.4741 | Train acc.: 0.9052 | Test acc.: 0.8727\n",
      "\n",
      "Epoch:23 | Train loss: 0.3009 | Test loss: 0.3906 | Train acc.: 0.9075 | Test acc.: 0.8833\n",
      "\n",
      "Epoch:24 | Train loss: 0.2786 | Test loss: 0.4848 | Train acc.: 0.9164 | Test acc.: 0.8682\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(25):  # num epochs\n",
    "    \n",
    "    # Training\n",
    "    model.train() # Set to train mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader): # Get data batch-wise\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # print(inputs.shape, inputs.dtype)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        # zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs) # forward pass\n",
    "        # print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels) # Get loss\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Optimize model weights\n",
    "\n",
    "        _, preds = torch.max(outputs, 1) # Get predictions\n",
    "        running_loss += loss.detach() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # Get loss and accuracy\n",
    "    train_loss = (running_loss / len(trainset))\n",
    "    train_loss_list.append(train_loss.item())\n",
    "    train_accuracy = (running_corrects.float() / len(trainset))\n",
    "\n",
    "    # Testing\n",
    "    model.eval() # Set to eval mode\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    y = []; yhat = []\n",
    "\n",
    "    for i, data in enumerate(valloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        with torch.no_grad(): # Don't build computation graph for testing\n",
    "            outputs = model(inputs)\n",
    "        # print(outputs.shape, labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y.append(labels.tolist())\n",
    "        yhat.append(preds.tolist())\n",
    "        running_loss += loss.detach() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    # Get loss and accuracy\n",
    "    test_loss = (running_loss / len(valset))\n",
    "    test_loss_list.append(test_loss.item())\n",
    "    test_accuracy = (running_corrects.float() / len(valset))\n",
    "\n",
    "    acc = test_accuracy.item()\n",
    "    if(acc > best_acc):\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(),\"checkpoint/vgg16_bn.pth\")\n",
    "\n",
    "    # Display loss, accuracy values after each epoch\n",
    "    print(\"Epoch:{} | Train loss: {:.4f} | Test loss: {:.4f} | Train acc.: {:.4f} | Test acc.: {:.4f}\\n\"\n",
    "              .format(epoch, train_loss.item(),test_loss.item(),train_accuracy.item(),test_accuracy.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16().to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoint/vgg16_bn.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3906 | Test acc.: 0.8833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model.eval() # Set to eval mode\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "y = []; yhat = []\n",
    "\n",
    "for i, data in enumerate(valloader):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    with torch.no_grad(): # Don't build computation graph for testing\n",
    "        outputs = model(inputs)\n",
    "    # print(outputs.shape, labels.shape)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y.append(labels.tolist())\n",
    "    yhat.append(preds.tolist())\n",
    "    running_loss += loss.detach() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "# Get loss and accuracy\n",
    "test_loss = (running_loss / len(valset))\n",
    "test_loss_list.append(test_loss.item())\n",
    "test_accuracy = (running_corrects.float() / len(valset))\n",
    "\n",
    "# Display loss, accuracy values after each epoch\n",
    "print(\"Test loss: {:.4f} | Test acc.: {:.4f}\\n\"\n",
    "            .format(test_loss.item(),test_accuracy.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENT\n",
    "\n",
    "model = tent.configure_model(model)\n",
    "params, param_names = tent.collect_params(model)\n",
    "optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "tented_model = tent.Tent(model, optimizer)\n",
    "\n",
    "tented_model = tented_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.4565 | Test acc.: 0.8721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Testing\n",
    "tented_model.eval() # Set to eval mode\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "y = []; yhat = []\n",
    "\n",
    "for i, data in enumerate(valloader):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    # labels = labels.type(torch.LongTensor)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    with torch.no_grad(): # Don't build computation graph for testing\n",
    "        outputs = tented_model(inputs)\n",
    "    # print(outputs.shape, labels.shape)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y.append(labels.tolist())\n",
    "    yhat.append(preds.tolist())\n",
    "    running_loss += loss.detach() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "# Get loss and accuracy\n",
    "test_loss = (running_loss / len(valset))\n",
    "test_loss_list.append(test_loss.item())\n",
    "test_accuracy = (running_corrects.float() / len(valset))\n",
    "\n",
    "# Display loss, accuracy values after each epoch\n",
    "print(\"Test loss: {:.4f} | Test acc.: {:.4f}\\n\"\n",
    "            .format(test_loss.item(),test_accuracy.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.8624   brightness.npy\n",
      "Average: 0.5894   contrast.npy\n",
      "Average: 0.7181   defocus_blur.npy\n",
      "Average: 0.7433   elastic_transform.npy\n",
      "Average: 0.7428   fog.npy\n",
      "Average: 0.6635   frost.npy\n",
      "Average: 0.6365   gaussian_blur.npy\n",
      "Average: 0.4881   gaussian_noise.npy\n",
      "Average: 0.4285   glass_blur.npy\n",
      "Average: 0.5507   impulse_noise.npy\n",
      "Average: 0.7652   jpeg_compression.npy\n",
      "Average: 0.6363   motion_blur.npy\n",
      "Average: 0.7145   pixelate.npy\n",
      "Average: 0.8387   saturate.npy\n",
      "Average: 0.5898   shot_noise.npy\n",
      "Average: 0.7123   snow.npy\n",
      "Average: 0.7688   spatter.npy\n",
      "Average: 0.6133   speckle_noise.npy\n",
      "Average: 0.6532   zoom_blur.npy\n",
      "Mean:  0.6692326153579511\n"
     ]
    }
   ],
   "source": [
    "model = VGG16().to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoint/vgg16_bn.pth\"))\n",
    "\n",
    "chalPath = 'data/CIFAR-10-C/'\n",
    "chals = sorted(os.listdir(chalPath))\n",
    "\n",
    "chal_labels = valset.test_labels\n",
    "chal_labels = torch.Tensor(chal_labels)\n",
    "chal_labels = chal_labels.long()\n",
    "\n",
    "def preprocess_test(X):\n",
    "\n",
    "    N, H, W, C = X.shape\n",
    "    Y = torch.zeros(N, C, H, W)\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)  \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean,std),\n",
    "    ])\n",
    "\n",
    "    for n in range(len(X)):\n",
    "        Y[n] =  transform_test(X[n])\n",
    "\n",
    "    return Y\n",
    "\n",
    "model.eval()\n",
    "avg_list = []\n",
    "\n",
    "for challenge in range(len(chals)):\n",
    "    chal_data = np.load(chalPath + chals[challenge])\n",
    "    # chal_data = np.transpose(chal_data, (0,3,1,2))\n",
    "\n",
    "    avg = 0\n",
    "    for j in range(5):\n",
    "        chal_temp_data = chal_data[j * 10000:(j + 1) * 10000]\n",
    "        chal_temp_data = preprocess_test(chal_temp_data)\n",
    "\n",
    "        chal_dataset = torch.utils.data.TensorDataset(chal_temp_data, chal_labels)\n",
    "        chal_loader = torch.utils.data.DataLoader(chal_dataset, batch_size=128)\n",
    "        chal_error = 0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in chal_loader:\n",
    "                # cost, err, probs = net.sample_eval(x, y, Nsamples=10, logits=False)\n",
    "                # preds_list.append(probs.cpu().numpy())\n",
    "                # chal_error += err.cpu().numpy()\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                outputs = model(x)\n",
    "                correct += torch.sum(torch.argmax(outputs,1) == y)\n",
    "            # print(err)\n",
    "\n",
    "        # print(chal_error)\n",
    "        chal_acc = (correct/len(chal_dataset)).item()\n",
    "        avg += chal_acc\n",
    "        # print(round(chal_acc,4))\n",
    "    \n",
    "    avg /= 5\n",
    "    avg_list.append(avg)\n",
    "    print(\"Average:\", round(avg,4),\" \", chals[challenge])\n",
    "\n",
    "print(\"Mean: \", np.mean(avg_list))\n",
    "list1 = avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"vgg_base.npy\",avg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 0.8673   brightness.npy\n",
      "Average: 0.8253   contrast.npy\n",
      "Average: 0.8466   defocus_blur.npy\n",
      "Average: 0.7994   elastic_transform.npy\n",
      "Average: 0.8373   fog.npy\n",
      "Average: 0.7853   frost.npy\n",
      "Average: 0.8352   gaussian_blur.npy\n",
      "Average: 0.7477   gaussian_noise.npy\n",
      "Average: 0.6253   glass_blur.npy\n",
      "Average: 0.7055   impulse_noise.npy\n",
      "Average: 0.7775   jpeg_compression.npy\n",
      "Average: 0.8077   motion_blur.npy\n",
      "Average: 0.8045   pixelate.npy\n",
      "Average: 0.8531   saturate.npy\n",
      "Average: 0.7747   shot_noise.npy\n",
      "Average: 0.7687   snow.npy\n",
      "Average: 0.7929   spatter.npy\n",
      "Average: 0.7678   speckle_noise.npy\n",
      "Average: 0.8294   zoom_blur.npy\n",
      "Mean:  0.7921652429982234\n"
     ]
    }
   ],
   "source": [
    "# Tented\n",
    "\n",
    "chalPath = 'data/CIFAR-10-C/'\n",
    "chals = sorted(os.listdir(chalPath))\n",
    "\n",
    "chal_labels = valset.test_labels\n",
    "chal_labels = torch.Tensor(chal_labels)\n",
    "chal_labels = chal_labels.long()\n",
    "\n",
    "def preprocess_test(X):\n",
    "\n",
    "    N, H, W, C = X.shape\n",
    "    Y = torch.zeros(N, C, H, W)\n",
    "    mean = (0.4914, 0.4822, 0.4465)\n",
    "    std = (0.2023, 0.1994, 0.2010)  \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean,std),\n",
    "    ])\n",
    "\n",
    "    for n in range(len(X)):\n",
    "        Y[n] =  transform_test(X[n])\n",
    "\n",
    "    return Y\n",
    "\n",
    "avg_list = []\n",
    "\n",
    "for challenge in range(len(chals)):\n",
    "    chal_data = np.load(chalPath + chals[challenge])\n",
    "    # chal_data = np.transpose(chal_data, (0,3,1,2))\n",
    "\n",
    "    avg = 0\n",
    "    for j in range(5):\n",
    "\n",
    "        # Load tented model\n",
    "        model = VGG16()\n",
    "        model.load_state_dict(torch.load(\"checkpoint/vgg16_bn.pth\"))\n",
    "        \n",
    "        net = tent.configure_model(model)\n",
    "        params, param_names = tent.collect_params(net)\n",
    "        optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "        tented_model = tent.Tent(net, optimizer)\n",
    "\n",
    "        tented_model = tented_model.to(device)\n",
    "\n",
    "        \n",
    "        chal_temp_data = chal_data[j * 10000:(j + 1) * 10000]\n",
    "        chal_temp_data = preprocess_test(chal_temp_data)\n",
    "\n",
    "        chal_dataset = torch.utils.data.TensorDataset(chal_temp_data, chal_labels)\n",
    "        chal_loader = torch.utils.data.DataLoader(chal_dataset, batch_size=128)\n",
    "        chal_error = 0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        tented_model.eval()\n",
    "        \n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in chal_loader:\n",
    "                # cost, err, probs = net.sample_eval(x, y, Nsamples=10, logits=False)\n",
    "                # preds_list.append(probs.cpu().numpy())\n",
    "                # chal_error += err.cpu().numpy()\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                outputs = tented_model(x)\n",
    "                correct += torch.sum(torch.argmax(outputs,1) == y)\n",
    "            # print(err)\n",
    "\n",
    "        # print(chal_error)\n",
    "        chal_acc = (correct/len(chal_dataset)).item()\n",
    "        avg += chal_acc\n",
    "        # print(round(chal_acc,4))\n",
    "    \n",
    "    avg /= 5\n",
    "    avg_list.append(avg)\n",
    "    print(\"Average:\", round(avg,4),\" \", chals[challenge])\n",
    "\n",
    "print(\"Mean: \", np.mean(avg_list))\n",
    "list2 = avg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"vgg_tent.npy\",avg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1 = np.load(\"vgg_base.npy\")\n",
    "# list2 = np.load(\"vgg_tent.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAGDCAYAAAALTociAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xm4HGWZ9/HvnQ3CIkQIGjaDskkIxBAIKIIIhEUBlVFZRo3oiygg4uAQV6I4gs44KKOScZBNkUUGBCSKILLIMkIwQNgDBghrwk4Uwknu94+qE5vDOUknleo+J+f7ua660rV0PXcv6fPrp5+qisxEkiRJ0rIZ0O4CJEmSpL7MQC1JkiRVYKCWJEmSKjBQS5IkSRUYqCVJkqQKDNSSJElSBQZqSVItImJyRPyivL1hRLwUEQPbVMuUiPh6O9qWtOIzUEtaahFxdUQ8GxErtbsW9Q2Z+XBmrpaZCxa3XURMjIg/VWmru31k5mGZeXyV/fbQ1qIvDZL6LwO1pKUSESOBdwMJ7FtTG4Pq2G9v1a5e2yp6a8397b0jqXcwUEtaWh8HbgLOAD7RuTAito+IJxqDVkR8MCJuL28PiIhJEfFARDwdEedHxBvLdSMjIiPiUxHxMHBVufxX5T6fj4hrI2JUw77XiohLI+KFiLg5Ir7d2CsZEZtHxBUR8UxE3BsRH+npAUXEJyPi7oh4MSIejIjPdFm/X0RML9t6ICL2LJe/MSJOj4jHyh77X5fLX9dDWj6+jcvbZ0TEKRExNSLmAbtExPsi4i9lG49ExOQu998xIm6IiOfK9RMjYtuIeLIxREbE/hExvYfHeUY59OGK8rFeExFvaeY5667mbva/UbnPFyPiCmDthnWdr/GghufowXLbv0bEwRHxdmAKsEM5POS5cts1IuKsiJgTEQ9FxNciYkDDfq6PiJMi4hngvB72cUZEfLuhnv8XETPLx3pJRKzb5bU6LCLuL1/XH0dEdPN49wS+Any0bOu2iPhwREzrst2/NLw3lvk1kNSLZaaTk5NT0xMwE/gcsA3wKvCmhnUPALs3zP8KmFTe/gJFEF8fWAn4b+Ccct1Iih7vs4BVgaHl8kOA1cvtfwBMb9j3ueW0CrAF8Ajwp3LdquX8J4FBwFhgLjCqh8f0PuBtQAA7A38DxpbrtgOeB3an6IRYD9i8XHcZRYAbBgwGdi6XT+yspaGNBDYub59R7vNd5T5XBt4DjC7ntwKeBD5Qbr8h8CJwYNnOWsCYct1dwF4N7VwE/EsPj/OMcj87lc/pD5t9zrqruZv93wj8Z7nvncq2ftHlNR5UtvUCsFm5bkRDO909d2cBF5fvhZHAfcCnGrbvAI4s9z20h32cAXy7vP3e8rGNLWv9L+DaLq/Vb4A1y+d+DrBnD8/p5M7HWM6vBDwDvL1h2V+A/au+Bk5OTr13ansBTk5OfWcCdqQI0WuX8/cARzes/zZwWnl7dWAe8JZy/m5g14ZtR5T7GtQQtt66mLbXLLdZAxhY3nezLm13BpOPAtd1uf9/A8c1+Th/DRzVcL+TutlmBLAQGNbNuu4CXddAfdYSavhBZ7vAl4GLetjuWODs8vYbKb4MjOhh2zOAcxvmVwMWABss6TlbUs1l8OwAVm1Y9kt6DtTPAftTfnnq6bkrX+tXgC0aln0GuLph+4ebeP7P4B+B+mfA97o8D68CIxteqx0b1p9P+cWwm8c9mYZAXS47Bfi38vYo4FlgpaqvgZOTU++dHPIhaWl8Avh9Zs4t539Jw7CPcv5DURys+CHg1sx8qFz3FuCicsjCcxQBewHwpob7P9J5IyIGRsSJ5RCLF4BZ5aq1geEUweyR7u5btjW+s62yvYOBN3f3oCJir4i4qfyZ/Tlgb/4xXGEDip73rjYAnsnMZ7vbZxMa6yUixkfEH8thDc8DhzVRA8AvgH0iYjXgIxSB7PFm2s3Mlyh6U9eluefsNTV3sS7wbGbOa1j2UHcbltt8lOIxPh4Rl0XE5j3sd21gSJd9PUTxS0EzdfVU66L9lc/D0132+UTD7b9RBN9mnQkcVA4T+Rhwfma+0l29y/AaSOqFPHhDUlMiYihFYBsYEZ1hYyVgzYjYOjNvy8y7IuIhYC/gIIqA3ekR4JDMvL6bfY8sb2bD4oOA/YDdKML0GhQ9fUHxE3wHxfCR+8rtN+jS1jWZuXsTj2sl4H8pxoZfnJmvluNdO8fMPkIxHKSrR4A3RsSamflcl3XzKIaidLbRXSDKLvO/BH5EMXzj5Yj4Af8I1I9QDD15/U4yH42IG4EPUoS3U7p/pIssep7KEP5G4DGae8661tzocWBYRKzaEKo37Ok+mXk5cHn5vvo28D/842DXRnMpeo/fQjG8pXO/jy6mrsXVCcXjbRy3vCrFMJpHe7xHz17XVmbeFBHzKR7PQeXUqMprIKkXsodaUrM+QNGjvAUwppzeDlxHEUY7/RL4PMUY0V81LJ8C/FvnAVgRMTwi9ltMe6tT/NT/NEU4/U7niixOvXYhMDkiVil7Nxtr+A2waUR8LCIGl9O25UFvXQ2h+GIwB+iIiL2ACQ3rfwZ8MiJ2jeLAyvUiYvOyF/i3wE8iYljZxk7lfW4DRkXEmIhYmWJYwJKsTtHj/XJEbMdrQ9jZwG4R8ZGIGBTFAZljGtafBfwrxRjsi5bQzt5RHOA4BDge+L/MfISle85ep/wl4hbgmxExJCJ2BPbpbtuIeFNE7FsG2VeAlyjeW1CMHV+/rK/ztT6f4r2zevn++SJFz3xPXrOPbvyS4jUdU36h+k75PMxq5rF209bIKA+SbHAWxRekjszsehrAWl4DSe1joJbUrE8Ap2dxPuEnOieK0HBw/ONME+dQHGB3VcPQECgOvroE+H1EvEhxgOL4xbR3FsXP8o9S9Eze1GX9ERS91k8APy/bfQUgM1+kCMUHUPT8PQF8lyI4v0a57ecpQtuzFEH2kob1f6Y4SOwkioPyruEfvZsfo+g9vQd4iuLASzLzPuBbwJXA/UAz51X+HPCt8rn5RllPZw0PUwxD+ReK4QHTga0b7ntRWdNFXYZcdOeXwHHlfrahGFKwVM/ZYhxE8Zo+U7ZxVg/bDSgfy2PltjtTPH4ozvByJ/BERHS+f46k6PV/kOK5/CVw2mLq6G4fi2TmH4CvU/wy8TjFLxAHNPUIX6/zS+PTEXFrw/KfA1uW/3ZV52sgqQ0ic0m/jElS7xcR3wXenJmfWOLGK6CIeAD4TGZeuZhtzgBmZ+bXWlZYP1UOZXmK4mwx9zcsPwNfA2mFYw+1pD6pPF/vVlHYDvgUSx7usEKKiP0pxvJe1e5atMhngZsbw7SkFZcHJUrqq1anGOaxLkVP4PcpzlXcr0TE1RTj2j+WmQvbXI6AiJhFcVDrB9pciqQWcciHJEmSVIFDPiRJkqQKDNSSJElSBX1uDPXaa6+dI0eObHcZkiRJWsFNmzZtbmYOX9J2fS5Qjxw5kltuuaXdZUiSJGkFV179d4kc8iFJkiRVYKCWJEmSKjBQS5IkSRX0uTHUkiRJfU1m0tHRgdf/6J0igkGDBhERy3R/A7UkSVLNOjo6GDBgAAMGDFjm0KZ6ZCYLFy6ko6ODwYMHL9M+HPIhSZJUs8w0TPdSEcGAAQMq/XpgoJYkSWoBw3TvVfW1MVBLkiT1AwMHDmTMmDFsvfXWjB07lhtuuKHdJTXljDPO4Igjjqi8TZ0cQy1JktRiIyddtlz3N+vE9y1xm6FDhzJ9+nQALr/8cr785S9zzTXXLNc6+it7qCVJkvqZF154gWHDhgHw0ksvseuuuzJ27FhGjx7NxRdfDMC8efN43/vex9Zbb82WW27JeeedB8C0adPYeeed2Wabbdhjjz14/PHHX7f/iRMn8tnPfpZddtmFt771rVxzzTUccsghvP3tb2fixImLtjvnnHMYPXo0W265Jccee+yi5aeffjqbbropO++8M9dff/2i5XPmzGH//fdn2223Zdttt33Nunayh1qSJKkf+Pvf/86YMWN4+eWXefzxx7nqqqsAWHnllbnooot4wxvewNy5c9l+++3Zd999+d3vfse6667LZZcVvenPP/88r776KkceeSQXX3wxw4cP57zzzuOrX/0qp5122uvae/bZZ7nqqqu45JJL2Geffbj++us59dRT2XbbbZk+fTrrrLMOxx57LNOmTWPYsGFMmDCBX//614wfP57jjjuOadOmscYaa7DLLrvwjne8A4CjjjqKo48+mh133JGHH36YPfbYg7vvvrt1T2IPDNSSJEn9QOOQjxtvvJGPf/zjzJgxg8zkK1/5Ctdeey0DBgzg0Ucf5cknn2T06NEcc8wxHHvssbz//e/n3e9+NzNmzGDGjBnsvvvuACxYsIARI0Z0294+++xDRDB69Gje9KY3MXr0aABGjRrFrFmzeOihh3jPe97D8OHDATj44IO59tprAV6z/KMf/Sj33XcfAFdeeSV33XXXojZeeOEFXnzxxRqeraVjoJYkSepndthhB+bOncucOXOYOnUqc+bMYdq0aQwePJiRI0fy8ssvs+mmmzJt2jSmTp3Kl7/8ZSZMmMAHP/hBRo0axY033rjENlZaaSUABgwYsOh253xHRweDBvUcQ3s668bChQu58cYbGTp06FI+4no5hnp5mLxGz5MkSVIvc88997BgwQLWWmstnn/+edZZZx0GDx7MH//4Rx566CEAHnvsMVZZZRX++Z//mWOOOYZbb72VzTbbjDlz5iwK1K+++ip33nnnMtUwfvx4rrnmGubOncuCBQs455xz2HnnnRk/fjxXX301Tz/9NK+++iq/+tWvFt1nwoQJ/OhHP1o039nj3m72UEuSJPUDnWOoobjQzJlnnsnAgQM5+OCD2WeffRg3bhxjxoxh8803B+COO+7gS1/6EgMGDGDw4MGccsopDBkyhAsuuIDPf/7zPP/883R0dPCFL3yBUaNGLXU9I0aM4IQTTmCXXXYhM9l7773Zb7/9AJg8eTI77LADI0aMYOzYsSxYsACAk08+mcMPP5ytttqKjo4OdtppJ6ZMmbKcnqFlF33tmvLjxo3LW265pS1t93SKm1krH9TznSY/X1M1kiSpr5g/fz5DhgxpdxlajO5eo4iYlpnjlnRfh3xIkiRJFRioJUmSpAocQy1JUn+zuIPmHaooLTV7qCVJkqQKDNSSJElSBQ750PLjT4iSJKkfsodakiRpBff0008zZswYxowZw5vf/GbWW2+9RfPz589fqn1deOGF3HPPPUt1n46ODtZcc82lus+yWH/99Xnuuecqb7O07KGWJGkF1fP1E1pciF5veV9NeQm/BK+11lqLrio4efJkVlttNY455phlaurCCy9kwIABiy4AI3uopXp4KXpJUh9x5plnst122zFmzBg+97nPsXDhwkU9ypMmTWLrrbdmhx124KmnnuK6665j6tSpHH300YwZM4ZZs2Zx//33s8cee7DNNtuw0047cd999wHwwAMPMH78eLbddlsmT57cbdszZ85kyy235JBDDmHUqFF8/OMf5/LLL+ed73wnm266KZ0X85s7dy777rsvW221Fe985zuZMWMGAHPmzGH33Xdn7NixfPazn6XxgoXdPa66GKgl1ccvFpLUq82YMYOLLrqIG264genTp9PR0cG5554LwPPPP8/OO+/Mbbfdxg477MBpp53Gu9/9bvbee29OOukkpk+fzsiRIzn00EP5yU9+wrRp0zjhhBM44ogjADjyyCM56qijuPnmmxk+fHiPNdx7770cc8wx3HHHHdx+++1ccMEF3HDDDZxwwgmceOKJAHz9619n/Pjx3H777UyePJmJEycCcNxxx7HLLrtw6623sueee/LYY48t8XHVwSEfkiRJ/dSVV17JzTffzLhxxdW1//73v7PBBhsAMHToUPbaay8AttlmG6677rrX3f+5557jpptuYv/991+0rKOjA4Abb7yRSy+9FICPfexjHHfccd3WsPHGG7PFFlsAsMUWW7DbbrsBMHr0aE444QQA/vSnP3HZZcUQpgkTJjBx4kTmzZvHtddey9SpUwHYb7/9WH311Zf4uOpgoJYkSeqnMpNDDjmE448//jXLOzo6GDJkyKL5gQMHLgrKXe+/9tprLxqf3SgiiIgl1rDSSisVN76/GQPufZyVfncNzP4GA+bOp+Pxxxe107XdxnaafVx1ccjHiqKnn9b9eV2SJPVgt9124/zzz2fu3LlAcTaQhx9+eLH3WX311XnxxRcBGDZsGCNGjOCiiy4CYOHChdx2220AbL/99px//vkAnH322ZXq3GmnnRbt48orr2T99ddn1VVXfc3ySy+9dFFdy/K4qjBQS5Ik9VOjR4/muOOOY7fddmOrrbZiwoQJPPnkk4u9z4EHHsh3vvOdRQclnnvuuUyZMoWtt96aUaNG8Zvf/AaAk08+mZNOOontttuOl156qVKd3/rWt7jhhhvYaqut+MY3vsHpp58OwDe/+U2uvPJKxo4dy9VXX8166623zI+riujahd7bjRs3LjuP+Gy1nk8/dFDPd2rVBU16w0VVekMNvUVPz4XPQ7m8nz0PUpv06r9b/cz8+fNfM4RC3fj+Zt0v/5d7W9J8d69RREzLzHFLuq891JIkSVIFBmpJkiSpAgO1JEmSVEGtgToi9oyIeyNiZkRM6mb9GhFxaUTcFhF3RsQn66xHkiSpXfracWv9SdXXprbzUEfEQODHwO7AbODmiLgkM+9q2Oxw4K7M3CcihgP3RsTZmTm/rrokSf2YB0+rTSKChQsXMmDAgKbOzazWyUwWLlxY6XWp88Iu2wEzM/NBgIg4F9gPaAzUCawexSNYDXgGeP1ZwyVJWlEY6vulQYMG0dHRwYIFC9pdSi/Ww1lQ5tffzxoRDBq07LG4zkC9HvBIw/xsYHyXbX4EXAI8BqwOfDQzF3bdUUQcChwKsOGGG9ZSrFYgnqpNktTLRASDBw9udxm924s9XHilD5xusM4x1N31m3cdoLIHMB1YFxgD/Cgi3vC6O2X+NDPHZea44cOHL/9KJUmSpGVUZ6CeDWzQML8+RU90o08CF2ZhJvBXYPMaa5IkSZKWqzqHfNwMbBIRGwGPAgcAXS/N9DCwK3BdRLwJ2Ax4sMaaJEmSeheHKvZ5tQXqzOyIiCOAy4GBwGmZeWdEHFaunwIcD5wREXdQDBE5NjPn1lWTJEmStLzV2UNNZk4FpnZZNqXh9mPAhDprkCRJkupUa6CW1Eb+hChJUkt46XFJkiSpAnuoJUmt4QVNJK2gDNSSJKn1/IKlFYhDPiRJkqQK7KGWJEn9Uwt7yUdOuqzHdbNWXq5NqQ0M1JIkSf2dZ4aqxEAtSVpu7IWT1B85hlqSJEmqwEAtSZIkVWCgliRJkiowUEuSJEkVGKglSZKkCjzLh6QVm6eCkiTVzB5qSZIkqQJ7qNUn9YZz3faGGiRJUvvZQy1JkiRVYKCWJEmSKjBQS5IkSRUYqCVJkqQKDNSSJElSBQZqSZIkqQIDtSRJklSBgVqSJEmqwAu7aKn1dEETL2YiSZL6IwO1JEk1sPNB6j8M1JIkaYXmlxvVzTHUkiRJUgX2UEtSfzB5jcWse751dUjSCsgeakmSJKkCA7UkSZJUgYFakiRJqsBALUmSJFVgoJYkSZIqMFBLkiRJFRioJUmSpAoM1JIkSVIFBmpJkiSpAgO1JEmSVIGBWpIkSarAQC1JkiRVYKCWJEmSKjBQS5IkSRUMancBkpbdyEmX9bhu1sotLESSpH7MHmpJkiSpAgO1JEmSVIGBWpIkSarAMdSSJElqiRX12B97qCVJkqQKDNSSJElSBQZqSZIkqQIDtSRJklSBgVqSJEmqwLN8SKpkRT1iW31bT+9L35OS6mAPtSRJklSBgVqSJEmqwEAtSZIkVeAYakmq2+Q1FrPu+dbVIUmqhT3UkiRJUgUGakmSJKkCA7UkSZJUgWOoJUmS+gGvG1CfWnuoI2LPiLg3ImZGxKQetnlPREyPiDsj4po665EkSZKWt9p6qCNiIPBjYHdgNnBzRFySmXc1bLMm8BNgz8x8OCLWqaseSZIkqQ519lBvB8zMzAczcz5wLrBfl20OAi7MzIcBMvOpGuuRJEmSlrs6A/V6wCMN87PLZY02BYZFxNURMS0iPl5jPZIkSdJyV+dBidHNsuym/W2AXYGhwI0RcVNm3veaHUUcChwKsOGGG9ZQqiRJkrRs6uyhng1s0DC/PvBYN9v8LjPnZeZc4Fpg6647ysyfZua4zBw3fPjw2gqWJEmSlladgfpmYJOI2CgihgAHAJd02eZi4N0RMSgiVgHGA3fXWJMkSZK0XNU25CMzOyLiCOByYCBwWmbeGRGHleunZObdEfE74HZgIXBqZs6oqyZJkiRpeav1wi6ZORWY2mXZlC7z/w78e511rEh6Oim7J2SXJPVG/t1Sf+ClxyVJkqQKDNSSJElSBQZqSZIkqYIlBuqIOCIihrWiGEmSJKmvaaaH+s3AzRFxfkTsGRHdXbBFkiRJ6peWGKgz82vAJsDPgInA/RHxnYh4W821SZIkSb1eU2OoMzOBJ8qpAxgGXBAR36uxNkmSJKnXW+J5qCPi88AngLnAqcCXMvPViBgA3A/8a70lSpIkSb1XMxd2WRv4UGY+1LgwMxdGxPvrKUuSJEnqG5oZ8jEVeKZzJiJWj4jxAJl5d12FSZIkSX1BM4H6FOClhvl55TJJkiSp32smUEd5UCJQDPWguaEikiRJ0gqvmUD9YER8PiIGl9NRwIN1FyZJkiT1Bc30NB8GnAx8DUjgD8ChdRYlSVp6Iydd1uO6WSu3sBBJ6meWGKgz8ynggBbUIkmSJPU5zZyHemXgU8AoYFEfR2YeUmNdkiRJUp/QzBjqnwNvBvYArgHWB16ssyhJkiSpr2gmUG+cmV8H5mXmmcD7gNH1liVJkiT1Dc0E6lfLf5+LiC2BNYCRtVUkSZIk9SHNnOXjpxExjOIsH5cAqwFfr7UqSZIkqY9YbKCOiAHAC5n5LHAt8NaWVCVJkiT1EYsd8lFeFfGIFtUiSZIk9TnNjKG+IiKOiYgNIuKNnVPtlUmSJEl9QDNjqDvPN314w7LE4R+SJElSU1dK3KgVhUiSJEl9UTNXSvx4d8sz86zlX44kSZLUtzQz5GPbhtsrA7sCtwIGakmSJPV7zQz5OLJxPiLWoLgcuSRJktTvNXOWj67+BmyyvAuRJEmS+qJmxlBfSnFWDygC+BbA+XUWJUmSJPUVzYyh/o+G2x3AQ5k5u6Z6JEmSpD6lmUD9MPB4Zr4MEBFDI2JkZs6qtTJJkiSpD2hmDPWvgIUN8wvKZZIkSVK/10ygHpSZ8ztnyttD6itJkiRJ6juaCdRzImLfzpmI2A+YW19JkiRJUt/RzBjqw4CzI+JH5fxsoNurJ0pSO4ycdFmP62at3MJCJEn9UjMXdnkA2D4iVgMiM1+svyxJkiSpb1jikI+I+E5ErJmZL2XmixExLCK+3YriJEmSpN6umTHUe2Xmc50zmfkssHd9JUmSJEl9RzOBemBErNQ5ExFDgZUWs70kSZLUbzRzUOIvgD9ExOkUlyA/BDiz1qokSZKkPqKZgxK/FxF3ALsCARyfmZfXXpkkSZLUBzTTQ01m/hb4bc21SJIkSX1OM2f52D4ibo6IlyJifkQsiIgXWlGcJEmS1Ns1c1Dij4ADgfuBocCngf+qsyhJkiSpr2h2yMfMiBiYmQuA0yPihprrkiRJkvqEZgL13yJiCDA9Ir4HPA6sWm9ZkiRJUt/QzJCPj5XbHQHMAzYA9q+zKEmSJKmvaOa0eQ+VN18GvllvOZIkSVLf0kwPtSRJkqQeGKglSZKkCpoO1BHhgYiSJElSF81c2OWdEXEXcHc5v3VE/KT2yiRJkqQ+oJke6pOAPYCnATLzNmCnOouSJEmS+oqmhnxk5iNdFi2ooRZJkiSpz2nmwi6PRMQ7gSwv8PJ5yuEfkiRJUn/XTKA+DPghsB4wG/g9cHidRUlSXzNy0mU9rpu1cgsLkSS1XDMXdpkLHNyCWiRJkqQ+Z4mBOiJO7mbx88AtmXnx8i9JkiRJ6juaOShxZWAMcH85bQW8EfhURPygxtokSZKkXq+ZMdQbA+/NzA6AiDiFYhz17sAdNdYmSZIk9XrN9FCvBzReJXFVYN3MXAC8UktVkiRJUh/RTA/194DpEXE1EBQXdflOeSnyK2usTZIkSer1lthDnZk/A94J/LqcdszMUzNzXmZ+aXH3jYg9I+LeiJgZEZMWs922EbEgIv5paR+AJEmS1E5NXSkReBl4HHgG2Dgilnjp8YgYCPwY2AvYAjgwIrboYbvvApc3W7QkSZLUWzRz2rxPA0cB6wPTge2BG4H3LuGu2wEzM/PBcj/nAvsBd3XZ7kjgf4Ftl6pySZIkqRdopof6KIqw+1Bm7gK8A5jTxP3WAx5pmJ9dLlskItYDPghMaapaSZIkqZdpJlC/nJkvA0TESpl5D7BZE/eLbpZll/kfAMeWZwzpeUcRh0bELRFxy5w5zWR5SZIkqTWaOcvH7IhYk+KAxCsi4lngsWbuB2zQML9+N/cbB5wbEQBrA3tHREdm/rpxo8z8KfBTgHHjxnUN5ZIkSVLbLDFQZ+YHy5uTI+KPwBrA75rY983AJhGxEfAocABwUJd9b9R5OyLOAH7TNUxLkiRJvdliA3VEDABuz8wtATLzmmZ3nJkdEXEExdk7BgKnZeadEXFYud5x05IkSerzFhuoM3NhRNwWERtm5sNLu/PMnApM7bKs2yCdmROXdv+SJElSuzUzhnoEcGdE/BmY17kwM/etrSpJkiSpj2gmUH+z9iokSZKkPqqZgxKviYi3AJtk5pURsQrFmGhJkiSp31vieagj4v8BFwD/XS5aj+IUepIkSVK/18yFXQ4H3gW8AJCZ9wPr1FmUJEmS1Fc0E6hfycz5nTMRMYjXX/FQkiRJ6peaCdTXRMRXgKERsTvwK+DSesuSJEmS+oZmAvUkYA5wB/AZivNKf63OoiRJkqS+opnT5u0HnJWZ/1N3MZIkSVJf00wP9b7AfRHx84h4XzmGWpIkSRJNBOrM/CSwMcXY6YOAByLi1LoLkyRJkvqCpnqbM/PViPgtxdlDlpoiAAARE0lEQVQ9hlIMA/l0nYVJkiRJfUEzF3bZMyLOAGYC/wScCoyouS5JkiSpT2imh3oicC7wmcx8pd5yJEmSpL5liYE6Mw9onI+IdwEHZebhtVUlSZIk9RFNjaGOiDEUByR+BPgrcGGdRUmSJEl9RY+BOiI2BQ4ADgSeBs4DIjN3aVFtkiRJUq+3uB7qe4DrgH0ycyZARBzdkqokSZKkPmJxZ/nYH3gC+GNE/E9E7ApEa8qSJEmS+oYeA3VmXpSZHwU2B64GjgbeFBGnRMSEFtUnSZIk9WrNXClxXmaenZnvB9YHpgOTaq9MkiRJ6gOWGKgbZeYzmfnfmfneugqSJEmS+pKlCtSSJEmSXstALUmSJFVgoJYkSZIqMFBLkiRJFRioJUmSpAoM1JIkSVIFBmpJkiSpAgO1JEmSVIGBWpIkSarAQC1JkiRVYKCWJEmSKjBQS5IkSRUYqCVJkqQKDNSSJElSBQZqSZIkqQIDtSRJklSBgVqSJEmqwEAtSZIkVWCgliRJkiowUEuSJEkVGKglSZKkCgzUkiRJUgUGakmSJKkCA7UkSZJUgYFakiRJqsBALUmSJFVgoJYkSZIqMFBLkiRJFRioJUmSpAoM1JIkSVIFBmpJkiSpAgO1JEmSVIGBWpIkSarAQC1JkiRVYKCWJEmSKjBQS5IkSRUYqCVJkqQKDNSSJElSBQZqSZIkqQIDtSRJklSBgVqSJEmqoNZAHRF7RsS9ETEzIiZ1s/7giLi9nG6IiK3rrEeSJEla3moL1BExEPgxsBewBXBgRGzRZbO/Ajtn5lbA8cBP66pHkiRJqkOdPdTbATMz88HMnA+cC+zXuEFm3pCZz5azNwHr11iPJEmStNzVGajXAx5pmJ9dLuvJp4DfdrciIg6NiFsi4pY5c+YsxxIlSZKkauoM1NHNsux2w4hdKAL1sd2tz8yfZua4zBw3fPjw5ViiJEmSVM2gGvc9G9igYX594LGuG0XEVsCpwF6Z+XSN9UiSJEnLXZ091DcDm0TERhExBDgAuKRxg4jYELgQ+Fhm3ldjLZIkSVItauuhzsyOiDgCuBwYCJyWmXdGxGHl+inAN4C1gJ9EBEBHZo6rqyZJkiRpeatzyAeZORWY2mXZlIbbnwY+XWcNkiRJUp28UqIkSZJUgYFakiRJqsBALUmSJFVgoJYkSZIqMFBLkiRJFRioJUmSpAoM1JIkSVIFBmpJkiSpAgO1JEmSVIGBWpIkSarAQC1JkiRVYKCWJEmSKjBQS5IkSRUYqCVJkqQKDNSSJElSBQZqSZIkqQIDtSRJklSBgVqSJEmqwEAtSZIkVWCgliRJkiowUEuSJEkVGKglSZKkCgzUkiRJUgUGakmSJKkCA7UkSZJUgYFakiRJqsBALUmSJFVgoJYkSZIqMFBLkiRJFRioJUmSpAoM1JIkSVIFBmpJkiSpAgO1JEmSVIGBWpIkSarAQC1JkiRVYKCWJEmSKjBQS5IkSRUYqCVJkqQKDNSSJElSBQZqSZIkqQIDtSRJklSBgVqSJEmqwEAtSZIkVWCgliRJkiowUEuSJEkVGKglSZKkCgzUkiRJUgUGakmSJKkCA7UkSZJUgYFakiRJqsBALUmSJFVgoJYkSZIqMFBLkiRJFRioJUmSpAoM1JIkSVIFBmpJkiSpAgO1JEmSVIGBWpIkSarAQC1JkiRVYKCWJEmSKjBQS5IkSRUYqCVJkqQKag3UEbFnRNwbETMjYlI36yMiTi7X3x4RY+usR5IkSVreagvUETEQ+DGwF7AFcGBEbNFls72ATcrpUOCUuuqRJEmS6lBnD/V2wMzMfDAz5wPnAvt12WY/4Kws3ASsGREjaqxJkiRJWq7qDNTrAY80zM8uly3tNpIkSVKvFZlZz44jPgzskZmfLuc/BmyXmUc2bHMZcEJm/qmc/wPwr5k5rcu+DqUYEgKwGXBvLUUvu7WBudbQK2qA3lGHNViDNViDNVhDs3pDHdbQvbdk5vAlbTSoxgJmAxs0zK8PPLYM25CZPwV+urwLXF4i4pbMHGcN7a+ht9RhDdZgDdZgDdbQl+qwhmrqHPJxM7BJRGwUEUOAA4BLumxzCfDx8mwf2wPPZ+bjNdYkSZIkLVe19VBnZkdEHAFcDgwETsvMOyPisHL9FGAqsDcwE/gb8Mm66pEkSZLqUOeQDzJzKkVoblw2peF2AofXWUOL9IbhKNbwD72hDmsoWEPBGgrWULCGgjX8Q2+owxoqqO2gREmSJKk/8NLjkiRJUgUG6goi4rSIeCoiZrSxhg0i4o8RcXdE3BkRR7WhhpUj4s8RcVtZwzdbXUNDLQMj4i8R8Zs2tT8rIu6IiOkRcUubalgzIi6IiHvK98UOLW5/s/Lxd04vRMQXWllDWcfR5ftxRkScExErt6GGo8r272zlc9DdZ1NEvDEiroiI+8t/h7Whhg+Xz8XCiKj9SP4eavj38v/G7RFxUUSs2YYaji/bnx4Rv4+IdVtdQ8O6YyIiI2LtVtcQEZMj4tGGz4q9W11DufzIiLi3fG9+r9U1RMR5Dc/BrIiY3oYaxkTETZ1/uyJiuzbUsHVE3Fj+Db00It5QZw3LXWY6LeME7ASMBWa0sYYRwNjy9urAfcAWLa4hgNXK24OB/wO2b9Pz8UXgl8Bv2tT+LGDtdr0fyhrOBD5d3h4CrNnGWgYCT1Ccx7OV7a4H/BUYWs6fD0xscQ1bAjOAVSiOV7kS2KRFbb/uswn4HjCpvD0J+G4bang7xbUErgbGtel5mAAMKm9/t03Pwxsabn8emNLqGsrlG1CcOOChuj+3engeJgPH1P0+WEINu5T/N1cq59dpx2vRsP77wDfa8Dz8HtirvL03cHUbargZ2Lm8fQhwfKveG8tjsoe6gsy8FnimzTU8npm3lrdfBO6mxVebzMJL5ezgcmr54PyIWB94H3Bqq9vuLcpv9DsBPwPIzPmZ+VwbS9oVeCAzH2pD24OAoRExiCLUvu4c9zV7O3BTZv4tMzuAa4APtqLhHj6b9qP4skX57wdaXUNm3p2ZLbswVw81/L58PQBuorj+QatreKFhdlVq/rxczN+qk4B/rbv9JdTQMj3U8FngxMx8pdzmqTbUAEBEBPAR4Jw21JBAZ4/wGtT8edlDDZsB15a3rwD2r7OG5c1AvQKJiJHAOyh6iFvd9sDyZ6qngCsys+U1AD+g+OOwsA1td0rg9xExLYorfLbaW4E5wOnl0JdTI2LVNtTR6QBq/uPQncx8FPgP4GHgcYpz3P++xWXMAHaKiLUiYhWKXp8NlnCfOr0py/P8l/+u08ZaeotDgN+2o+GI+LeIeAQ4GPhGG9rfF3g0M29rddtdHFEOfzmt7mFIPdgUeHdE/F9EXBMR27ahhk7vBp7MzPvb0PYXgH8v35P/AXy5DTXMAPYtb3+Y9n5eLjUD9QoiIlYD/hf4Qpfej5bIzAWZOYait2e7iNiyle1HxPuBp7LLZevb4F2ZORbYCzg8InZqcfuDKH5GOyUz3wHMo/h5v+WiuKDTvsCv2tD2MIoe2Y2AdYFVI+KfW1lDZt5NMaTgCuB3wG1Ax2LvpJaJiK9SvB5nt6P9zPxqZm5Qtn9EK9suv+B9lTYE+S5OAd4GjKH44vv9NtQwCBgGbA98CTi/7CluhwNpQwdE6bPA0eV78mjKXzlb7BCKv5vTKIawzm9DDcvMQL0CiIjBFGH67My8sJ21lMMLrgb2bHHT7wL2jYhZwLnAeyPiFy2ugcx8rPz3KeAioNYDO7oxG5jd8AvBBRQBux32Am7NzCfb0PZuwF8zc05mvgpcCLyz1UVk5s8yc2xm7kTx82Y7ep46PRkRIwDKf2v9abs3i4hPAO8HDs5ywGYb/ZLW/7T9Noovm7eVn5nrA7dGxJtbWURmPll2xiwE/ofWf15C8Zl5YTl08c8Uv3DWeoBmd8qhaR8Czmt126VPUHxOQtEJ0vLXIjPvycwJmbkNxReLB1pdQxUG6j6u/Cb9M+DuzPzPNtUwvPNI+YgYShFm7mllDZn55cxcPzNHUgwzuCozW9ojGRGrRsTqnbcpDn5q6RlgMvMJ4JGI2KxctCtwVytraNDO3paHge0jYpXy/8iuFMcXtFRErFP+uyHFH8t2PR8Al1D80aT89+I21tI2EbEncCywb2b+rU01bNIwuy+t/7y8IzPXycyR5WfmbIqD259oZR2dX/BKH6TFn5elXwPvLevZlOJA7rltqGM34J7MnN2GtqEYM71zefu9tOHLf8Pn5QDga8CUxd+jl2n3UZF9eaL44/g48CrFB9Kn2lDDjhTjdm8HppfT3i2uYSvgL2UNM6j5COUm6nkPbTjLB8X45dvK6U7gq216/GOAW8rX49fAsDbUsArwNLBGG98H36QIKjOAn1Mexd/iGq6j+EJzG7BrC9t93WcTsBbwB4o/lH8A3tiGGj5Y3n4FeBK4vA01zAQeafi8rPsMG93V8L/l+/J24FJgvVbX0GX9LOo/y0d3z8PPgTvK5+ESYEQbahgC/KJ8PW4F3tuO1wI4AziszraX8DzsCEwrP6v+D9imDTUcRXGmsvuAEykvPthXJq+UKEmSJFXgkA9JkiSpAgO1JEmSVIGBWpIkSarAQC1JkiRVYKCWJEmSKjBQS1INImJBREyPiDsj4raI+GJ5flUiYlxEnLyY+46MiIOWoc3X3G9J7Szlvr+yPPYjSSsiT5snSTWIiJcyc7Xy9joUV8S7PjOPa+K+7wGOycz3L0V7gyjOJbtU91uK/S96PJKk1zJQS1INugbQiHgrcDPFZY13pgy+EbEz8MNyswR2Aq4A3g78FTgTOKWcxgEdwBcz848RMRF4H7AysCrFBXUa7/eXhnbeCJxGcQGivwGHZubtETEZ2LBcviHwg8x8Ta92RJwIfIniIhx3Ag8CczPzh+X6f6O4UMvtwLcoLuqzGXAt8LnMXBgREygutrMSxSWFP5mZLy3zEyxJvcigdhcgSf1BZj5YDvlYp8uqY4DDM/P6iFgNeBmYRENPc0T8S7mP0RGxOfD78jLJADsAW2XmM117tsv5Tt8E/pKZH4iI9wJnUVxVE2BzYBdgdeDeiDglM19tqH1SRByRmWPK/Y4ELgR+WD6mA4DtgNHlv1sADwG/Az4UEVdTXEp4t8ycFxHHAl+kCN+S1OcZqCWpdaKbZdcD/xkRZwMXZubsiNdttiPwXwCZeU9EPAR0BuorMvOZJtreEdi/3MdVEbFWRKxRrrssM18BXomIp4A3UVwOuFuZOSsino6Id5Tb/iUzny7r/nNmPggQEeeU7b5MEbKvL7cZAtzYRM2S1CcYqCWpBcohHwuApyiGZQCQmSdGxGXA3sBNEbFbd3dfzK7nNVtCN8s6x/y90rBsAc39bTgVmAi8mWIoSdd9Ns4HRfA/sKlKJamP8SwfklSziBgOTAF+lF0OXImIt2XmHZn5XeAWiuEXL1IMv+h0LXBwuf2mFGOd7+2mqa73a9S4j/dQjIF+YSkexqsRMbhh/iJgT2Bb4PKG5dtFxEblUJCPAn8CbgLeFREbl+2v0jBkRZL6PHuoJakeQyNiOjCY4kDCnwP/2c12X4iIXSh6hu8CfgssBDoi4jbgDOAnwJSIuKPc18TMfKWboSG3d7nfXxrWTQZOj4jbKQ5K/MRSPp6fArdHxK2ZeXBmzo+IPwLPZeaChu1uBE6kGE99LXBReVDiROCciFip3O5rwH1LWYMk9Uqe5UOStNTKHuhbgQ9n5v3lsvdQ02n7JKk3c8iHJGmpRMQWwEzgD51hWpL6M3uoJUmSpArsoZYkSZIqMFBLkiRJFRioJUmSpAoM1JIkSVIFBmpJkiSpAgO1JEmSVMH/ByZ9JjFGQepWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "types = np.arange(1,20)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "x_axis = np.arange(len(types))\n",
    "plt.bar(x_axis -0.1, list1, width=0.2, label = 'Base model')\n",
    "plt.bar(x_axis +0.1, list2, width=0.2, label = 'Tented model')\n",
    "\n",
    "plt.xticks(x_axis, types)\n",
    "plt.title(\"Average accuracy per distortion type\")\n",
    "plt.legend(loc = 'upper right', framealpha = 0.1)\n",
    "\n",
    "plt.xlabel(\"Distortion type\")\n",
    "plt.ylabel(\"Average accuracy\")\n",
    "plt.savefig(\"cifar10c_vgg.pdf\",bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31b8918c388efabf28e06d7aa829f320b99f50374aee3ccc5c6fe8cd01c3acd4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
